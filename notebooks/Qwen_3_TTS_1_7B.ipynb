{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéôÔ∏è Qwen3-TTS: Advanced Text-to-Speech AI\n",
        "\n",
        "<div align=\"center\">\n",
        "  \n",
        "[![Support](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support-FFDD00?style=for-the-badge&logo=buymeacoffee&logoColor=black)](https://buymeacoffee.com/lynettethecat)\n",
        "[![License](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge)](https://opensource.org/licenses/MIT)\n",
        "\n",
        "**Created by [Lynette](https://www.youtube.com/@LynetteTheCatOfficial)**\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "## üìå What is This Notebook?\n",
        "\n",
        "This notebook allows you to run Qwen3-TTS directly in your browser with GPU support ‚Äî no complex setup required.\n",
        "\n",
        "‚úÖ **Voice Cloning** - Clone any voice with just 3 seconds of audio  \n",
        "‚úÖ **Custom Voices** - 9 preset character voices in multiple languages  \n",
        "‚úÖ **Voice Design** - Create unique voices from text descriptions  \n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Features\n",
        "\n",
        "| Feature | Description | Speed |\n",
        "|---------|-------------|-------|\n",
        "| üé§ **Voice Cloning** | Clone any voice with reference audio | RTF 3.5-5x |\n",
        "| üé≠ **Custom Voice** | 9 preset voices (English, Chinese, Japanese, Korean, German, French, Spanish) | RTF 3.5-5x |\n",
        "| üé® **Voice Design** | Design voices from text descriptions | RTF 3.5-5x |\n",
        "| üåç **Multilingual** | Support for 9 languages | - |\n",
        "| ‚ö° **Optimized** | FP16 + SDPA + TF32 enabled | Max Speed |\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ How to Use\n",
        "\n",
        "1. **Run all cells** (Runtime ‚Üí Run all) or click ‚ñ∂Ô∏è on each cell\n",
        "2. **Wait for Gradio interface** to launch (~2-3 minutes for first model load)\n",
        "3. **Click the public link** that appears\n",
        "4. **Choose a tab** and start generating!\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Tips for Best Results\n",
        "\n",
        "### Voice Cloning\n",
        "- Use **clear reference audio** (3+ seconds)\n",
        "- Provide **transcript** for better quality\n",
        "- Enable **Fast Mode** for quicker results\n",
        "\n",
        "### Custom Voice\n",
        "- Try different voices to find your favorite\n",
        "- Use **style instructions** like \"speak slowly\" or \"cheerful tone\"\n",
        "\n",
        "### Voice Design\n",
        "- Be **specific** in descriptions: age, gender, emotion, accent\n",
        "- Example: *\"A young female, cheerful, speaking clearly with British accent\"*\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Technical Details\n",
        "\n",
        "- **Model**: Qwen3-TTS 1.7B (Base, CustomVoice, VoiceDesign)\n",
        "- **Hardware**: Google Colab T4 GPU\n",
        "- **Optimizations**: FP16 precision, SDPA attention, TF32\n",
        "- **Expected Speed**: RTF 5x (100 seconds for 20 seconds of audio)\n",
        "\n",
        "---\n",
        "\n",
        "## üì∫ More AI Tutorials\n",
        "\n",
        "---\n",
        "\n",
        "## üôè Credits\n",
        "\n",
        "- **Qwen Team** for the amazing TTS models\n",
        "- **Hugging Face** for model hosting\n",
        "- **AIQuest Academy** for this notebook\n",
        "\n",
        "---\n",
        "\n",
        "## üìú License\n",
        "\n",
        "This notebook is free to use and modify. Qwen3-TTS models are licensed under their respective terms.\n",
        "\n",
        "---\n",
        "\n",
        "**‚¨áÔ∏è Run the cells below to get started! ‚¨áÔ∏è**\n"
      ],
      "metadata": {
        "id": "Uz-xrjgdgkWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCrmZ6iRAPrB"
      },
      "outputs": [],
      "source": [
        "# Install with FlashAttention support\n",
        "# Install compatible Torch first\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.4.1+cu121 torchvision==0.19.1+cu121 torchaudio==2.4.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install ninja\n",
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install -U qwen-tts gradio huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import tempfile\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# Global variables\n",
        "current_model = None\n",
        "current_model_type = None\n",
        "\n",
        "# Enable PyTorch optimizations\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.conv.fp32_precision = 'tf32'\n",
        "torch.backends.cuda.matmul.fp32_precision = 'tf32'\n",
        "\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "def load_model(model_type):\n",
        "    \"\"\"Load model with SDPA optimization\"\"\"\n",
        "    global current_model, current_model_type\n",
        "\n",
        "    if current_model_type == model_type:\n",
        "        print(f\"‚úÖ Using cached {model_type} model\")\n",
        "        return current_model\n",
        "\n",
        "    if current_model is not None:\n",
        "        print(f\"Unloading {current_model_type} model...\")\n",
        "        del current_model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Loading {model_type} model (1.7B)...\")\n",
        "    start = time.time()\n",
        "\n",
        "    try:\n",
        "        if model_type == \"base\":\n",
        "            model_name = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
        "        elif model_type == \"custom\":\n",
        "            model_name = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\"\n",
        "        elif model_type == \"design\":\n",
        "            model_name = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\"\n",
        "\n",
        "        current_model = Qwen3TTSModel.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"cuda:0\",\n",
        "            attn_implementation=\"sdpa\"\n",
        "        )\n",
        "\n",
        "        current_model_type = model_type\n",
        "        load_time = time.time() - start\n",
        "\n",
        "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
        "        print(f\"‚úÖ Loaded in {load_time:.1f}s | GPU: {allocated:.2f}GB\")\n",
        "\n",
        "        return current_model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def voice_clone(text, reference_audio, ref_transcript, use_fast_mode):\n",
        "    \"\"\"Generate speech by cloning a reference voice\"\"\"\n",
        "    if not text or not reference_audio:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        total_start = time.time()\n",
        "        model = load_model(\"base\")\n",
        "        if model is None:\n",
        "            return None\n",
        "\n",
        "        print(f\"‚è±Ô∏è Creating prompt...\")\n",
        "        prompt_start = time.time()\n",
        "\n",
        "        if use_fast_mode or not ref_transcript:\n",
        "            prompt_items = model.create_voice_clone_prompt(\n",
        "                ref_audio=reference_audio,\n",
        "                x_vector_only_mode=True\n",
        "            )\n",
        "        else:\n",
        "            prompt_items = model.create_voice_clone_prompt(\n",
        "                ref_audio=reference_audio,\n",
        "                ref_text=ref_transcript,\n",
        "                x_vector_only_mode=False\n",
        "            )\n",
        "\n",
        "        prompt_time = time.time() - prompt_start\n",
        "        print(f\"   Prompt: {prompt_time:.1f}s\")\n",
        "\n",
        "        print(f\"‚è±Ô∏è Generating audio...\")\n",
        "        gen_start = time.time()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            wavs, sr = model.generate_voice_clone(\n",
        "                text=text,\n",
        "                voice_clone_prompt=prompt_items\n",
        "            )\n",
        "\n",
        "        gen_time = time.time() - gen_start\n",
        "\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        sf.write(temp_file.name, wavs[0], sr)\n",
        "\n",
        "        total_time = time.time() - total_start\n",
        "        audio_duration = len(wavs[0]) / sr\n",
        "        rtf = gen_time / audio_duration\n",
        "\n",
        "        print(f\"‚úÖ Done! Total: {total_time:.1f}s | Gen: {gen_time:.1f}s | Audio: {audio_duration:.1f}s | RTF: {rtf:.2f}x\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return temp_file.name\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in voice_clone: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def custom_voice(text, voice_name, instruction):\n",
        "    \"\"\"Generate speech using preset voices\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        total_start = time.time()\n",
        "        model = load_model(\"custom\")\n",
        "        if model is None:\n",
        "            return None\n",
        "\n",
        "        print(f\"‚è±Ô∏è Generating with voice: {voice_name}...\")\n",
        "        if instruction and instruction.strip():\n",
        "            print(f\"   Style instruction: '{instruction}'\")\n",
        "\n",
        "        gen_start = time.time()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            if instruction and instruction.strip():\n",
        "                wavs, sr = model.generate_custom_voice(\n",
        "                    text=text,\n",
        "                    speaker=voice_name,\n",
        "                    instruct=instruction\n",
        "                )\n",
        "            else:\n",
        "                wavs, sr = model.generate_custom_voice(\n",
        "                    text=text,\n",
        "                    speaker=voice_name\n",
        "                )\n",
        "\n",
        "        gen_time = time.time() - gen_start\n",
        "\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        sf.write(temp_file.name, wavs[0], sr)\n",
        "\n",
        "        total_time = time.time() - total_start\n",
        "        audio_duration = len(wavs[0]) / sr\n",
        "        rtf = gen_time / audio_duration\n",
        "\n",
        "        print(f\"‚úÖ Done! Total: {total_time:.1f}s | Gen: {gen_time:.1f}s | Audio: {audio_duration:.1f}s | RTF: {rtf:.2f}x\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return temp_file.name\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in custom_voice: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def voice_design(text, voice_description):\n",
        "    \"\"\"Generate speech from text description\"\"\"\n",
        "    if not text or not voice_description:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        total_start = time.time()\n",
        "        model = load_model(\"design\")\n",
        "        if model is None:\n",
        "            return None\n",
        "\n",
        "        print(f\"‚è±Ô∏è Generating...\")\n",
        "        gen_start = time.time()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            wavs, sr = model.generate_voice_design(\n",
        "                text=text,\n",
        "                instruct=voice_description\n",
        "            )\n",
        "\n",
        "        gen_time = time.time() - gen_start\n",
        "\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        sf.write(temp_file.name, wavs[0], sr)\n",
        "\n",
        "        total_time = time.time() - total_start\n",
        "        audio_duration = len(wavs[0]) / sr\n",
        "        rtf = gen_time / audio_duration\n",
        "\n",
        "        print(f\"‚úÖ Done! Total: {total_time:.1f}s | Gen: {gen_time:.1f}s | Audio: {audio_duration:.1f}s | RTF: {rtf:.2f}x\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return temp_file.name\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in voice_design: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Custom CSS for clean branding\n",
        "custom_css = \"\"\"\n",
        "/* Creator Badge */\n",
        ".creator-badge {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "    padding: 12px 20px;\n",
        "    border-radius: 8px;\n",
        "    text-align: center;\n",
        "    margin-bottom: 20px;\n",
        "    box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "}\n",
        "\n",
        ".creator-badge p {\n",
        "    color: white;\n",
        "    margin: 0;\n",
        "    font-size: 1em;\n",
        "    font-weight: 500;\n",
        "}\n",
        "\n",
        ".creator-badge strong {\n",
        "    font-weight: 700;\n",
        "    font-size: 1.1em;\n",
        "}\n",
        "\n",
        "/* Social Buttons */\n",
        ".social-buttons {\n",
        "    display: flex;\n",
        "    gap: 12px;\n",
        "    justify-content: center;\n",
        "    margin: 15px 0 25px 0;\n",
        "    flex-wrap: wrap;\n",
        "}\n",
        "\n",
        ".social-btn {\n",
        "    display: inline-flex;\n",
        "    align-items: center;\n",
        "    gap: 8px;\n",
        "    padding: 10px 20px;\n",
        "    border-radius: 8px;\n",
        "    text-decoration: none;\n",
        "    font-weight: 600;\n",
        "    font-size: 14px;\n",
        "    transition: all 0.2s ease;\n",
        "    box-shadow: 0 2px 8px rgba(0,0,0,0.15);\n",
        "}\n",
        "\n",
        ".social-btn:hover {\n",
        "    transform: translateY(-2px);\n",
        "    box-shadow: 0 4px 12px rgba(0,0,0,0.25);\n",
        "}\n",
        "\n",
        ".youtube-btn {\n",
        "    background: #FF0000;\n",
        "    color: white !important;\n",
        "}\n",
        "\n",
        ".twitter-btn {\n",
        "    background: #000000;\n",
        "    color: white !important;\n",
        "}\n",
        "\n",
        "/* Footer */\n",
        ".aiquest-footer {\n",
        "    text-align: center;\n",
        "    padding: 15px;\n",
        "    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
        "    border-radius: 8px;\n",
        "    margin-top: 20px;\n",
        "    font-size: 0.9em;\n",
        "    color: #555;\n",
        "}\n",
        "\n",
        ".aiquest-footer strong {\n",
        "    color: #667eea;\n",
        "}\n",
        "\n",
        "/* Button styling */\n",
        ".gr-button-primary {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;\n",
        "    border: none !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks(title=\"Qwen3-TTS - By AIQuest Academy\", css=custom_css) as demo:\n",
        "\n",
        "    # Creator Badge\n",
        "    gr.HTML(\"\"\"\n",
        "        <div class=\"creator-badge\">\n",
        "            <p>üì∫ Notebook created by <strong>Lynette</strong></p>\n",
        "        </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # Main Title\n",
        "    gr.Markdown(\"# üéôÔ∏è Qwen3-TTS: Voice Clone, Custom Voice & Voice Design\")\n",
        "    gr.Markdown(\"### Advanced Text-to-Speech AI | Using 1.7B models with SDPA optimization\")\n",
        "\n",
        "    with gr.Tab(\"üé§ Voice Cloning\"):\n",
        "        gr.Markdown(\"### Clone any voice with 3+ seconds of audio\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                clone_text = gr.Textbox(\n",
        "                    label=\"Text to Synthesize\",\n",
        "                    placeholder=\"Enter text (shorter = faster)...\",\n",
        "                    lines=4\n",
        "                )\n",
        "                clone_audio = gr.Audio(\n",
        "                    label=\"Reference Audio (3+ seconds)\",\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "                clone_transcript = gr.Textbox(\n",
        "                    label=\"Transcript (Optional - improves quality)\",\n",
        "                    placeholder=\"What's said in the audio...\",\n",
        "                    lines=3\n",
        "                )\n",
        "                clone_fast_mode = gr.Checkbox(\n",
        "                    label=\"Fast Mode (skip transcript)\",\n",
        "                    value=True\n",
        "                )\n",
        "                clone_btn = gr.Button(\"üéµ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column():\n",
        "                clone_output = gr.Audio(label=\"Generated Speech\")\n",
        "                gr.Markdown(\"\"\"\n",
        "                **Expected Timing (T4 GPU):**\n",
        "                - First use: ~2-3 Minutes (model load)\n",
        "                - RTF: 3.5-5x\n",
        "                - 10s audio ‚âà 35-50s\n",
        "                - 20s audio ‚âà 70-100s\n",
        "                \"\"\")\n",
        "\n",
        "        clone_btn.click(\n",
        "            voice_clone,\n",
        "            inputs=[clone_text, clone_audio, clone_transcript, clone_fast_mode],\n",
        "            outputs=clone_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üé≠ Custom Voice\"):\n",
        "        gr.Markdown(\"### Use 9 preset character voices with style control\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                custom_text = gr.Textbox(\n",
        "                    label=\"Text to Synthesize\",\n",
        "                    placeholder=\"Enter text...\",\n",
        "                    lines=4\n",
        "                )\n",
        "                custom_voice_name = gr.Dropdown(\n",
        "                    choices=[\n",
        "                        \"serena\",     # Female voice\n",
        "                        \"vivian\",     # Female voice\n",
        "                        \"ono_anna\",   # Female voice (Japanese-style)\n",
        "                        \"sohee\",      # Female voice (Korean-style)\n",
        "                        \"aiden\",      # Male voice\n",
        "                        \"dylan\",      # Male voice\n",
        "                        \"eric\",       # Male voice\n",
        "                        \"ryan\",       # Male voice\n",
        "                        \"uncle_fu\"    # Male voice (Chinese-style)\n",
        "                    ],\n",
        "                    label=\"Voice Character\",\n",
        "                    value=\"serena\"\n",
        "                )\n",
        "                custom_instruction = gr.Textbox(\n",
        "                    label=\"Style Instruction (Optional)\",\n",
        "                    placeholder=\"e.g., 'speak slowly and cheerfully'\",\n",
        "                    lines=2\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"\"\"\n",
        "                **Voice Guide:**\n",
        "                - **Female**: serena, vivian, ono_anna, sohee\n",
        "                - **Male**: aiden, dylan, eric, ryan, uncle_fu\n",
        "\n",
        "                **Style Instructions Examples:**\n",
        "                - \"speak slowly and clearly\"\n",
        "                - \"cheerful and energetic\"\n",
        "                - \"whisper softly\"\n",
        "                - \"authoritative tone\"\n",
        "                \"\"\")\n",
        "\n",
        "                custom_btn = gr.Button(\"üéµ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column():\n",
        "                custom_output = gr.Audio(label=\"Generated Speech\")\n",
        "                gr.Markdown(\"**Timing**: RTF 3.5-5x\")\n",
        "\n",
        "        custom_btn.click(\n",
        "            custom_voice,\n",
        "            inputs=[custom_text, custom_voice_name, custom_instruction],\n",
        "            outputs=custom_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üé® Voice Design\"):\n",
        "        gr.Markdown(\"### Design a unique voice from text description\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                design_text = gr.Textbox(\n",
        "                    label=\"Text to Synthesize\",\n",
        "                    placeholder=\"Enter text...\",\n",
        "                    lines=4\n",
        "                )\n",
        "                design_description = gr.Textbox(\n",
        "                    label=\"Voice Description\",\n",
        "                    placeholder=\"A young female, cheerful, speaking clearly\",\n",
        "                    lines=4\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"\"\"\n",
        "                **Description Tips:**\n",
        "                - Age: young / middle-aged / elderly\n",
        "                - Gender: male / female\n",
        "                - Emotion: cheerful / serious / calm / excited\n",
        "                - Style: clear / soft / authoritative / energetic\n",
        "\n",
        "                **Examples:**\n",
        "                - \"A middle-aged male, deep and authoritative, speaking slowly\"\n",
        "                - \"A young female, cheerful and bubbly, speaking energetically\"\n",
        "                - \"An elderly man, warm and gentle, speaking softly\"\n",
        "                \"\"\")\n",
        "\n",
        "                design_btn = gr.Button(\"üéµ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column():\n",
        "                design_output = gr.Audio(label=\"Generated Speech\")\n",
        "                gr.Markdown(\"**Timing**: RTF 3.5-5x\")\n",
        "\n",
        "        design_btn.click(\n",
        "            voice_design,\n",
        "            inputs=[design_text, design_description],\n",
        "            outputs=design_output\n",
        "        )\n",
        "\n",
        "    # Performance Info\n",
        "    gr.Markdown(\"---\")\n",
        "    with gr.Accordion(\"‚ö° Performance & Technical Info\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### Performance Metrics\n",
        "        - **RTF 5x (100s for 20s audio) is normal for T4 GPU**\n",
        "        - HuggingFace Spaces use A100 GPUs (5-10x faster hardware)\n",
        "        - Optimizations active: FP16, SDPA, TF32\n",
        "\n",
        "        ### Speed Tips\n",
        "        - Use shorter text for faster results\n",
        "        - Enable Fast Mode in Voice Cloning\n",
        "        - First generation includes model loading time\n",
        "\n",
        "        ### Features\n",
        "        - ‚úÖ Voice Cloning with optional transcript\n",
        "        - ‚úÖ 9 Custom preset voices with style instructions\n",
        "        - ‚úÖ Voice Design from text descriptions\n",
        "        - ‚úÖ Multilingual support (9 languages)\n",
        "\n",
        "        ### Models Used\n",
        "        - Qwen3-TTS-12Hz-1.7B-Base (Voice Cloning)\n",
        "        - Qwen3-TTS-12Hz-1.7B-CustomVoice (Preset Voices)\n",
        "        - Qwen3-TTS-12Hz-1.7B-VoiceDesign (AI Voice Creation)\n",
        "        \"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üéôÔ∏è Qwen3-TTS Notebook\")\n",
        "print(\"üì∫ Created by: Lynette\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nStarting Qwen3-TTS with optimizations...\")\n",
        "demo.launch(share=True, debug=True, theme=gr.themes.Soft())"
      ],
      "metadata": {
        "id": "A_mtXgllARXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
